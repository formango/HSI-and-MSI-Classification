{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SM4kogzPAniC"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "suRi9jsX-mbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4f4c74-ec4b-4b25-8b1d-95d07dba21b8"
      },
      "source": [
        "pip install spectral"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spectral\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/9b/db2e160f891441b2f576e31caaa93c283ce5f82d625173830abd7ab3cbc3/spectral-0.22.2.tar.gz (184kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 14.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 11.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 40kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 81kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 92kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 102kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 112kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 122kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 133kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 143kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 153kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 163kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 174kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from spectral) (1.19.5)\n",
            "Building wheels for collected packages: spectral\n",
            "  Building wheel for spectral (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spectral: filename=spectral-0.22.2-cp37-none-any.whl size=212938 sha256=bf79e313895d4d28c8948c05906fad914c393d7e325c8443bc50b7fa8ec92575\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/00/da/ac778d1ab6e196cb7f56d104d4dfdfc0aad4e2b208275c0726\n",
            "Successfully built spectral\n",
            "Installing collected packages: spectral\n",
            "Successfully installed spectral-0.22.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lAKqodT-sKk"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "import spectral\n",
        "import torch, math\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from scipy.io import loadmat, savemat\n",
        "import random\n",
        "from time import time\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zHmDD44-5RR"
      },
      "source": [
        "Setting the seed of GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAKfj4w7-3Zv"
      },
      "source": [
        "def seed_torch(seed = 612):\n",
        "\trandom.seed(seed)\n",
        "\tos.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现\n",
        "\tnp.random.seed(seed)\n",
        "\ttorch.manual_seed(seed)\n",
        "\ttorch.cuda.manual_seed(seed)\n",
        "\ttorch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
        "\ttorch.backends.cudnn.benchmark = False\n",
        "\ttorch.backends.cudnn.deterministic = True\n",
        "seed_torch() \n",
        "\n",
        "# Setting parameters of model \n",
        "\n",
        "# the number of bands\n",
        "channel_hsi = 63\n",
        "channel_msi = 2\n",
        "\n",
        "# parameters of loss finctions\n",
        "alpha = 0.01\n",
        "beta = 0.01\n",
        "\n",
        "windowSize = 11\n",
        "class_num = 20\n",
        "batch_size = 64\n",
        "\n",
        "# parameters of optimizer\n",
        "lr = 0.001  # learning rate \n",
        "momentum = 0.9 # momentum of SGD\n",
        "betas = (0.9, 0.999) # betas of Adam\n",
        "num_epochs = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDjYmMhU_XTC"
      },
      "source": [
        "# 1. Feature extraction network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaTZVb3s-864"
      },
      "source": [
        "class HSINet(nn.Module):\n",
        "  def __init__(self, channel_hsi):\n",
        "    super(HSINet, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(channel_hsi, 256, 3, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(256)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(256, 128, 3)\n",
        "    self.bn2 = nn.BatchNorm2d(128)\n",
        "    self.conv3 = nn.Conv2d(128, 128, 3)\n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = F.relu(self.bn1(self.conv1(x)))\n",
        "    x = F.relu(self.bn2(self.conv2(x)))\n",
        "    x = F.relu(self.bn3(self.conv3(x)))\n",
        "    return x\n",
        "\n",
        "class MSINet(nn.Module):\n",
        "  def __init__(self, channel_msi):\n",
        "    super(MSINet, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(channel_msi, 128, 3, padding =1)\n",
        "    self.bn1 = nn.BatchNorm2d(128)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(128, 128, 3)\n",
        "    self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(128, 128, 3)\n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = F.relu(self.bn1(self.conv1(x)))\n",
        "    x = F.relu(self.bn2(self.conv2(x)))\n",
        "    x = F.relu(self.bn3(self.conv3(x)))\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNGYOU-n_Wln"
      },
      "source": [
        "Define normalization and dropout layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpP2m1lx_dhl"
      },
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, size, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.eps = eps\n",
        "        self.a_2 = nn.Parameter(torch.ones(size))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "\n",
        "class Dropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Dropout, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.dropout(x, p = 0.2, training=self.training)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3sdRkzu_VIV"
      },
      "source": [
        "Define cross attention layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laGokoIy_y--"
      },
      "source": [
        "class CAM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CAM, self).__init__()      \n",
        "        k_size = 3 \n",
        "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)\n",
        "        # self.conv1 = nn.Conv2d(9, 7, 1) # 81 为特征图像空间特征大小\n",
        "        # self.conv2 = nn.Conv2d(7, 49, 1, stride=1, padding=0)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "\n",
        "    def get_attention(self, a):\n",
        "\n",
        "        input_a = a\n",
        "        a = a.mean(3)\n",
        "        a = a.transpose(1, 3)\n",
        "        # a= F.relu(self.conv1(a))\n",
        "        # a= self.conv2(a)\n",
        "        a = self.conv(a.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)\n",
        "        a = a.transpose(1, 3)\n",
        "\n",
        "        a = a.unsqueeze(3)\n",
        "        a = torch.mean(input_a * a, -1)\n",
        "        a = F.softmax(a / 0.025, dim=-1) +1\n",
        "        return a \n",
        "\n",
        "    def forward(self, f1, f2):\n",
        "\n",
        "        b, n1, c, h, w = f1.size()\n",
        "        n2 = f2.size(1)\n",
        "\n",
        "        f1 = f1.view(b, n1, c, -1) \n",
        "        f2 = f2.view(b, n2, c, -1)\n",
        "\n",
        "        f1_norm = F.normalize(f1, p=2, dim=2, eps=1e-12)\n",
        "        f2_norm = F.normalize(f2, p=2, dim=2, eps=1e-12)\n",
        "        \n",
        "        f1_norm = f1_norm.transpose(2, 3).unsqueeze(2)\n",
        "        f2_norm = f2_norm.unsqueeze(1)\n",
        "\n",
        "        a1 = torch.matmul(f1_norm, f2_norm) \n",
        "        a2 = a1.transpose(3, 4) \n",
        "\n",
        "        a1 = self.get_attention(a1)\n",
        "        a2 = self.get_attention(a2)\n",
        "        f1 = f1 * a1\n",
        "        f1 = f1.view(b, c, h, w)\n",
        "        f2 = f2 * a2\n",
        "        f2 = f2.view(b, c, h, w)\n",
        "        return f1, f2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmAGqpMmAa-S"
      },
      "source": [
        "# 2. The proposed deep feature interaction network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14WtUYaPAKIJ"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, channel_hsi, channel_msi, class_num):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.featnet1 = HSINet(channel_hsi)\n",
        "        self.featnet2 = MSINet(channel_msi)\n",
        "        self.cam = CAM()\n",
        "        self.proj_norm = LayerNorm(64)\n",
        "        self.fc1 = nn.Linear(1 * 1 * 128, 64)\n",
        "        self.fc2 = nn.Linear(64, class_num)\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "    def forward(self, x, y):\n",
        "\n",
        "        # Pre-process Image Feature\n",
        "        feature_1 = self.featnet1(x)\n",
        "        feature_2 = self.featnet2(y)\n",
        "\n",
        "        hsi_feat = feature_1.unsqueeze(1)\n",
        "        lidar_feat = feature_2.unsqueeze(1)\n",
        "        hsi, lidar = self.cam(hsi_feat, lidar_feat)\n",
        "        x = self.xcorr_depthwise(hsi, lidar)\n",
        "        y = self.xcorr_depthwise(lidar, hsi)\n",
        "        x1 = x.contiguous().view(x.size(0), -1)\n",
        "        y1 = y.contiguous().view(y.size(0), -1)\n",
        "        x = x1 + y1\n",
        "        x = F.relu(self.proj_norm(self.fc1(x)))\n",
        "        \n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        # hsi = hsi.contiguous().view(x.size(0), -1)\n",
        "        # lidar = lidar.contiguous().view(x.size(0), -1)\n",
        "        return feature_1, feature_2, x1, y1, x\n",
        "\n",
        "    def xcorr_depthwise11(self, x, kernel):\n",
        "        batch = kernel.size(0)\n",
        "        channel = kernel.size(1)\n",
        "        x = x.view(1, batch * channel, x.size(2), x.size(3))\n",
        "        kernel = kernel.view(batch, channel, kernel.size(2), kernel.size(3))\n",
        "        out = F.conv2d(x, kernel, groups= 1)\n",
        "        # out = F.relu(out)\n",
        "        out = out.view(batch, 1, out.size(2), out.size(3))\n",
        "        return out\n",
        "\n",
        "    def xcorr_depthwise(self, x, kernel):\n",
        "        batch = kernel.size(0)\n",
        "        channel = kernel.size(1)\n",
        "        x = x.view(1, batch * channel, x.size(2), x.size(3))\n",
        "        kernel = kernel.view(batch * channel, 1, kernel.size(2), kernel.size(3))\n",
        "        out = F.conv2d(x, kernel, groups=batch*channel)\n",
        "        # out = F.relu(out)\n",
        "        out = out.view(batch, channel, out.size(2), out.size(3))\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM4kogzPAniC"
      },
      "source": [
        "# 3. Data processing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A_Ndtr3AuKV"
      },
      "source": [
        "def max_min_mean(img):\n",
        "  \"\"\"\n",
        "    calculate the max value ,min value ,mean value from the image.\n",
        "  \"\"\"\n",
        "  print('max: ',np.max(img),'min: ',np.min(img),'mean: ',np.mean(img))\n",
        "\n",
        "def c(img):\n",
        "  \"\"\"\n",
        "    map the image to [0,255]\n",
        "  \"\"\"\n",
        "  return ( img - np.min(img) ) / ( np.max(img)-np.min(img) ) * 255\n",
        "\n",
        "\n",
        "def applyPCA(X, numComponents):\n",
        "  \"\"\"\n",
        "    apply PCA to the image to reduce dimensionality \n",
        "  \"\"\"\n",
        "  newX = np.reshape(X, (-1, X.shape[2]))\n",
        "  pca = PCA(n_components=numComponents, whiten=True)\n",
        "  newX = pca.fit_transform(newX)\n",
        "  newX = np.reshape(newX, (X.shape[0], X.shape[1], numComponents))\n",
        "  return newX\n",
        "\n",
        "def addZeroPadding(X, margin=2):\n",
        "  \"\"\"\n",
        "    add zero padding to the image\n",
        "  \"\"\"\n",
        "  newX = np.zeros((\n",
        "      X.shape[0] + 2 * margin,\n",
        "      X.shape[1] + 2 * margin,\n",
        "      X.shape[2]\n",
        "            ))\n",
        "  newX[margin:X.shape[0]+margin, margin:X.shape[1]+margin, :] = X\n",
        "  return newX\n",
        "\n",
        "\n",
        "def createImgCube(X ,gt ,pos:list ,windowSize=25):\n",
        "  \"\"\"\n",
        "    create Cube from pos list\n",
        "    return imagecube gt nextPos\n",
        "  \"\"\"\n",
        "  margin = (windowSize-1)//2\n",
        "  zeroPaddingX = addZeroPadding(X, margin=margin)\n",
        "  dataPatches = np.zeros((pos.__len__(), windowSize, windowSize, X.shape[2]))\n",
        "  if( pos[-1][1]+1 != X.shape[1] ):\n",
        "    nextPos = (pos[-1][0] ,pos[-1][1]+1)\n",
        "  elif( pos[-1][0]+1 != X.shape[0] ):\n",
        "    nextPos = (pos[-1][0]+1 ,0)\n",
        "  else:\n",
        "    nextPos = (0,0)\n",
        "  return np.array([zeroPaddingX[i:i+windowSize, j:j+windowSize, :] for i,j in pos ]),\\\n",
        "  np.array([gt[i,j] for i,j in pos]) ,\\\n",
        "  nextPos\n",
        "\n",
        "\n",
        "def createPos(shape:tuple, pos:tuple, num:int):\n",
        "  \"\"\"\n",
        "    creatre pos list after the given pos\n",
        "  \"\"\"\n",
        "  if (pos[0]+1)*(pos[1]+1)+num >shape[0]*shape[1]:\n",
        "    num = shape[0]*shape[1]-( (pos[0])*shape[1] + pos[1] )\n",
        "  return [(pos[0]+(pos[1]+i)//shape[1] , (pos[1]+i)%shape[1] ) for i in range(num) ]\n",
        "\n",
        "def createPosWithoutZero(hsi, gt):\n",
        "  \"\"\"\n",
        "    creatre pos list without zero labels\n",
        "  \"\"\"\n",
        "  mask = gt > 0\n",
        "  return [(i,j) for i , row  in enumerate(mask) for j , row_element in enumerate(row) if row_element]\n",
        "\n",
        "def createImgPatch(lidar, pos:list, windowSize=25):\n",
        "  \"\"\"\n",
        "    return lidar Img patches\n",
        "  \"\"\"\n",
        "  margin = (windowSize-1)//2\n",
        "  zeroPaddingLidar = np.zeros((\n",
        "      lidar.shape[0] + 2 * margin,\n",
        "      lidar.shape[1] + 2 * margin\n",
        "            ))\n",
        "  zeroPaddingLidar[margin:lidar.shape[0]+margin, margin:lidar.shape[1]+margin] = lidar\n",
        "  return np.array([zeroPaddingLidar[i:i+windowSize, j:j+windowSize] for i,j in pos ])\n",
        "\n",
        "def minmax_normalize(array):    \n",
        "    amin = np.min(array)\n",
        "    amax = np.max(array)\n",
        "    return (array - amin) / (amax - amin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ4XnH3qBBCe"
      },
      "source": [
        "# 4. Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTJxj8OyBBXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58852986-d317-4486-b8cb-04859b46c0ee"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/data/'\n",
        "\n",
        "data_traingt = sio.loadmat(os.path.join(data_path, 'mask_train.mat'))['mask_train']\n",
        "data_testgt = sio.loadmat(os.path.join(data_path, 'mask_test.mat'))['mask_test']\n",
        "data_hsi = sio.loadmat(os.path.join(data_path, 'YC_hsi.mat'))['trento_hsi']\n",
        "data_msi = sio.loadmat(os.path.join(data_path, 'YC_msi.mat'))['trento_lidar']\n",
        "# data_msi = h5py.File(os.path.join(data_path, 'HHK_msi.mat'))\n",
        "# data_msi = data_msi['HHK_msi'][:]\n",
        "# data_msi= np.transpose(data_msi,(2,1,0))\n",
        "\n",
        "data_hsi = minmax_normalize(data_hsi)\n",
        "data_msi = minmax_normalize(data_msi)\n",
        "height , width, c = data_msi.shape\n",
        "\n",
        "# training / testing set for 2D-CNN\n",
        "\n",
        "train_hsiCube, train_labels ,_ = createImgCube(data_hsi, data_traingt, createPosWithoutZero(data_hsi, data_traingt), windowSize=windowSize)\n",
        "train_hsiCube = torch.from_numpy(train_hsiCube.transpose(0,3,1,2)).float()\n",
        "train_patches, _ ,_ = createImgCube(data_msi, data_traingt, createPosWithoutZero(data_hsi, data_traingt), windowSize=windowSize)\n",
        "train_patches = torch.from_numpy(train_patches.transpose(0,3,1,2)).float()\n",
        "\n",
        "test_hsiCube, test_labels , _ = createImgCube(data_hsi, data_testgt, createPosWithoutZero(data_hsi, data_testgt), windowSize=windowSize)\n",
        "test_hsiCube = torch.from_numpy(test_hsiCube.transpose(0,3,1,2)).float()\n",
        "test_patches, _, _ = createImgCube(data_msi, data_testgt, createPosWithoutZero(data_msi, data_testgt), windowSize=windowSize)\n",
        "test_patches = torch.from_numpy(test_patches.transpose(0,3,1,2)).float()\n",
        "\n",
        "print (train_hsiCube.shape)\n",
        "print (test_hsiCube.shape)\n",
        "\n",
        "print(\"Creating dataloader\")\n",
        "\n",
        "class TrainDS(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        self.len = train_labels.shape[0]\n",
        "        self.hsi = torch.FloatTensor(train_hsiCube)\n",
        "        self.lidar = torch.FloatTensor(train_patches)\n",
        "        self.labels = torch.LongTensor(train_labels - 1)\n",
        "    def __getitem__(self, index):\n",
        "        return self.hsi[index], self.lidar[index], self.labels[index]\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\"\"\" Testing dataset\"\"\"\n",
        "class TestDS(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        self.len = test_labels.shape[0]\n",
        "        self.hsi = torch.FloatTensor(test_hsiCube)\n",
        "        self.lidar = torch.FloatTensor(test_patches)\n",
        "        self.labels = torch.LongTensor(test_labels - 1)\n",
        "    def __getitem__(self, index):\n",
        "        return self.hsi[index], self.lidar[index], self.labels[index]\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# creat trainloader and testloader\n",
        "trainset = TrainDS()\n",
        "testset  = TestDS()\n",
        " \n",
        "# def _init_fn(worker_id):\n",
        "#     np.random.seed(int(seed)+worker_id)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = trainset, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = testset, batch_size = batch_size, shuffle = False, num_workers = 0)\n",
        "\n",
        "print(\"Finish!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([819, 63, 11, 11])\n",
            "torch.Size([30214, 63, 11, 11])\n",
            "Creating dataloader\n",
            "Finish!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxQ57lsoBsIk"
      },
      "source": [
        "# 5. The loss function\n",
        "\n",
        "1.   loss1: The consistency loss\n",
        "2.   loss2: The distinctive loss\n",
        "3.   loss3: The classification loss\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgM_E3XHBg7C"
      },
      "source": [
        "def calc_label_sim(label_1,label_2):\n",
        "\n",
        "    batch_size = label_1.shape[0]\n",
        "    label = torch.zeros(batch_size, class_num).scatter_(1, label_1.unsqueeze(1).cpu(), 1)\n",
        "    sim = label.float().mm(label.float().t()).cuda()\n",
        "    return sim\n",
        "def calc_loss(feature_1, feature_2, hsi_1, lidar_1, outputs, labels, alpha, beta):\n",
        "\n",
        "    cos = lambda x, y: x.mm(y.t()) / ((x ** 2).sum(1, keepdim=True).sqrt().mm((y ** 2).sum(1, keepdim=True).sqrt().t())).clamp(min=1e-6) / 2.\n",
        "    theta = cos(hsi_1, lidar_1)\n",
        "    sim = calc_label_sim(labels, labels)\n",
        "    theta1 = cos(hsi_1, hsi_1)\n",
        "    theta2 = cos(lidar_1, lidar_1)\n",
        "\n",
        "    term1= ((1+torch.exp(theta)).log() + sim * theta).mean()\n",
        "    term2 = ((1 + torch.exp(theta1)).log() + sim * theta1).mean()\n",
        "    term3 = ((1 + torch.exp(theta2)).log() + sim * theta2).mean()\n",
        "    loss2 = term1 + term2 + term3\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loss3 = criterion(outputs, labels)\n",
        "    loss1 = torch.mean(torch.pow(feature_1 - feature_2, 2))\n",
        "\n",
        "    loss_sum = loss3 + alpha * loss2 + beta * loss3\n",
        "    return loss_sum.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdMnyTbeCO6T"
      },
      "source": [
        "Define training and testing layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjBG9og2CPBV"
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i, (inputs_1, inputs_2, labels) in enumerate(train_loader):\n",
        "        inputs_1, inputs_2 = inputs_1.to(device), inputs_2.to(device)\n",
        "\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        feature_1, feature_2, hsi_1, lidar_1, outputs = model(inputs_1, inputs_2)\n",
        "        loss = calc_loss(feature_1, feature_2, hsi_1, lidar_1, outputs, labels, alpha =0.01, beta = 0.01)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print('[Epoch: %d] [loss avg: %.4f] [current loss: %.4f]' %(epoch + 1, total_loss/(epoch+1), loss.item()))\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    feature =[]\n",
        "    flabel = []\n",
        "    for inputs_1, inputs_2, labels in test_loader:\n",
        "  \n",
        "        inputs_1, inputs_2 = inputs_1.to(device), inputs_2.to(device)\n",
        "        _, _, _, _, outputs = model(inputs_1, inputs_2)\n",
        "        feature.append(outputs.detach().cpu().numpy())\n",
        "        outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
        "        if count == 0:\n",
        "            y_pred_test =  outputs\n",
        "            test_labels = labels\n",
        "            count = 1\n",
        "        else:\n",
        "            y_pred_test = np.concatenate((y_pred_test, outputs))\n",
        "            test_labels = np.concatenate((test_labels, labels))\n",
        "    classification = classification_report(test_labels, y_pred_test, digits=4)\n",
        "      \n",
        "    sio.savemat('feature.mat', {'feature': feature})\n",
        "    a = 0\n",
        "    for c in range(len(y_pred_test)):\n",
        "      if test_labels[c]==y_pred_test[c]:\n",
        "        a = a+1\n",
        "    sio.savemat('test_labels.mat', {'test_labels': test_labels})\n",
        "    print(classification)\n",
        "    print('%.2f' %(a/len(y_pred_test)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSAc_kbLAxP"
      },
      "source": [
        "# 6. Running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSy2Vxx_LA5P"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net(channel_hsi,channel_msi,class_num).to(device)\n",
        "\n",
        "params_to_update = list(model.parameters())\n",
        "\n",
        "# optimizer = torch.optim.Adam(params_to_update, lr=lr, betas=betas, eps=1e-8, weight_decay=0.0005)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=0.0005)\n",
        "\n",
        "# if num_epochs % 50 == 0:\n",
        "#     for p in optimizer.param_groups:p['lr'] *= 0.9\n",
        "#     lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
        "#     print (lr_list)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train(model, device, train_loader, optimizer, epoch) \n",
        "test(model, device, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR3aPwlILr4T"
      },
      "source": [
        "# 7. Record the test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jkC7NQTLsA4"
      },
      "source": [
        "from operator import truediv\n",
        "\n",
        "def AA_andEachClassAccuracy(confusion_matrix):\n",
        "    counter = confusion_matrix.shape[0]\n",
        "    list_diag = np.diag(confusion_matrix)\n",
        "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
        "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
        "    average_acc = np.mean(each_acc)\n",
        "    return each_acc, average_acc\n",
        "\n",
        "def reports(test_loader, name):\n",
        "    count = 0\n",
        "    for inputs, inputs_1, labels in test_loader:\n",
        "        inputs, inputs_1 = inputs.to(device), inputs_1.to(device)\n",
        "        _, _, _, _, outputs = model(inputs, inputs_1)\n",
        "\n",
        "        outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
        "        if count == 0:\n",
        "            y_pred = outputs\n",
        "            test_labels = labels\n",
        "            count = 1\n",
        "        else:\n",
        "            y_pred = np.concatenate((y_pred, outputs))\n",
        "            test_labels = np.concatenate((test_labels, labels))\n",
        "    if name == 'Houston':\n",
        "        target_names = ['Healthy grass', 'Stressed grass', 'Synthetic grass', 'Tree'\n",
        "            , 'Soil', 'Water', 'Residential', 'Commercial',\n",
        "                        'Road', 'Highway', 'Railway',\n",
        "                        'Parking lot 1', 'Parking lot 2', 'Tennis court', 'Running track']\n",
        "    elif name == 'Muufl':\n",
        "        target_names = ['Trees', 'Mostly grass', 'Mixed ground surface', 'Dirt and sand',\n",
        "                        'Road',\n",
        "                        'Water', 'Building shadow', 'Building', 'Sidewalk', 'Yellow curb',\n",
        "                        'Cloth panels']\n",
        "    elif name == 'HHK':\n",
        "        target_names = ['1', '2', '3', '4', '5', '6', '7', '8', '9n', '10',\n",
        "                        '11', '12', '13', '14', '15','16', '17', '18', '19', '20']\n",
        "\n",
        "    classification = classification_report(test_labels, y_pred, target_names=target_names)\n",
        "    oa = accuracy_score(test_labels, y_pred)\n",
        "    confusion = confusion_matrix(test_labels, y_pred)\n",
        "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
        "    kappa = cohen_kappa_score(test_labels, y_pred)\n",
        "\n",
        "    return classification, confusion, oa * 100, each_acc * 100, aa * 100, kappa * 100\n",
        "\n",
        "\"\"\"record the final result\"\"\"\n",
        "\n",
        "classification, confusion, oa, each_acc, aa, kappa = reports(test_loader, 'HHK')\n",
        "\n",
        "# print('The running time:', time() - start)\n",
        "sio.savemat('confusion.mat',{'confusion':confusion})\n",
        "\n",
        "print('Save confusion Finish！')\n",
        "\n",
        "classification = str(classification)\n",
        "confusion = str(confusion)\n",
        "\n",
        "file_name = \"classification_report.txt\"\n",
        "\n",
        "with open(file_name, 'w') as x_file:\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Overall accuracy (%)'.format(oa))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Average accuracy (%)'.format(aa))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{}'.format(classification))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{}'.format(confusion))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}