{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "suRi9jsX-mbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16151316-2241-4ae9-8b8e-6e2ea85b70d1"
      },
      "source": [
        "pip install spectral"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spectral in /usr/local/lib/python3.7/dist-packages (0.22.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from spectral) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lAKqodT-sKk"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "import spectral\n",
        "import torch, math\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from scipy.io import loadmat, savemat\n",
        "import random\n",
        "from time import time\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zHmDD44-5RR"
      },
      "source": [
        "Setting the seed of GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAKfj4w7-3Zv"
      },
      "source": [
        "# def seed_torch(seed = 612):\n",
        "# \trandom.seed(seed)\n",
        "# \tos.environ['PYTHONHASHSEED'] = str(seed) \n",
        "# \tnp.random.seed(seed)\n",
        "# \ttorch.manual_seed(seed)\n",
        "# \ttorch.cuda.manual_seed(seed)\n",
        "# \ttorch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
        "# \ttorch.backends.cudnn.benchmark = False\n",
        "# \ttorch.backends.cudnn.deterministic = True\n",
        "# seed_torch() \n",
        "\n",
        "# Setting parameters of model \n",
        "data_path = '/content/drive/MyDrive/data/'\n",
        "\n",
        "# the number of bands\n",
        "channel_hsi = 63\n",
        "channel_msi = 2\n",
        "\n",
        "# parameters of loss finctions\n",
        "alpha = 0.01\n",
        "beta = 0.01\n",
        "\n",
        "windowSize = 11\n",
        "valRatio = 0.2 # Ratio of validation sets\n",
        "class_num = 20\n",
        "batch_size = 64\n",
        "\n",
        "# parameters of optimizer\n",
        "lr = 0.001  # learning rate \n",
        "momentum = 0.9 # momentum of SGD\n",
        "betas = (0.9, 0.999) # betas of Adam\n",
        "num_epochs = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDjYmMhU_XTC"
      },
      "source": [
        "# 1. Feature extraction network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaTZVb3s-864"
      },
      "source": [
        "class HSINet(nn.Module):\n",
        "  def __init__(self, channel_hsi):\n",
        "    super(HSINet, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(channel_hsi, 256, 3, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(256)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(256, 128, 3)\n",
        "    self.bn2 = nn.BatchNorm2d(128)\n",
        "    self.conv3 = nn.Conv2d(128, 128, 3)\n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = F.relu(self.bn1(self.conv1(x)))\n",
        "    x = F.relu(self.bn2(self.conv2(x)))\n",
        "    x = F.relu(self.bn3(self.conv3(x)))\n",
        "    return x\n",
        "\n",
        "class MSINet(nn.Module):\n",
        "  def __init__(self, channel_msi):\n",
        "    super(MSINet, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(channel_msi, 128, 3, padding =1)\n",
        "    self.bn1 = nn.BatchNorm2d(128)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(128, 128, 3)\n",
        "    self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(128, 128, 3)\n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = F.relu(self.bn1(self.conv1(x)))\n",
        "    x = F.relu(self.bn2(self.conv2(x)))\n",
        "    x = F.relu(self.bn3(self.conv3(x)))\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNGYOU-n_Wln"
      },
      "source": [
        "Define normalization and dropout layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpP2m1lx_dhl"
      },
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, size, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.eps = eps\n",
        "        self.a_2 = nn.Parameter(torch.ones(size))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "\n",
        "class Dropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Dropout, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.dropout(x, p = 0.2, training=self.training)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3sdRkzu_VIV"
      },
      "source": [
        "Define cross attention layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laGokoIy_y--"
      },
      "source": [
        "class CAM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CAM, self).__init__()      \n",
        "        k_size = 3 \n",
        "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)\n",
        "        # self.conv1 = nn.Conv2d(9, 7, 1) # 81 is the spatial size of features\n",
        "        # self.conv2 = nn.Conv2d(7, 49, 1, stride=1, padding=0)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "\n",
        "    def get_attention(self, a):\n",
        "\n",
        "        input_a = a\n",
        "        a = a.mean(3)\n",
        "        a = a.transpose(1, 3)\n",
        "        # a= F.relu(self.conv1(a))\n",
        "        # a= self.conv2(a)\n",
        "        a = self.conv(a.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)\n",
        "        a = a.transpose(1, 3)\n",
        "\n",
        "        a = a.unsqueeze(3)\n",
        "        a = torch.mean(input_a * a, -1)\n",
        "        a = F.softmax(a / 0.025, dim=-1) +1\n",
        "        return a \n",
        "\n",
        "    def forward(self, f1, f2):\n",
        "\n",
        "        b, n1, c, h, w = f1.size()\n",
        "        n2 = f2.size(1)\n",
        "\n",
        "        f1 = f1.view(b, n1, c, -1) \n",
        "        f2 = f2.view(b, n2, c, -1)\n",
        "\n",
        "        f1_norm = F.normalize(f1, p=2, dim=2, eps=1e-12)\n",
        "        f2_norm = F.normalize(f2, p=2, dim=2, eps=1e-12)\n",
        "        \n",
        "        f1_norm = f1_norm.transpose(2, 3).unsqueeze(2)\n",
        "        f2_norm = f2_norm.unsqueeze(1)\n",
        "\n",
        "        a1 = torch.matmul(f1_norm, f2_norm) \n",
        "        a2 = a1.transpose(3, 4) \n",
        "\n",
        "        a1 = self.get_attention(a1)\n",
        "        a2 = self.get_attention(a2)\n",
        "        f1 = f1 * a1\n",
        "        f1 = f1.view(b, c, h, w)\n",
        "        f2 = f2 * a2\n",
        "        f2 = f2.view(b, c, h, w)\n",
        "        return f1, f2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmAGqpMmAa-S"
      },
      "source": [
        "# 2. The proposed deep feature interaction network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14WtUYaPAKIJ"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, channel_hsi, channel_msi, class_num):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.featnet1 = HSINet(channel_hsi)\n",
        "        self.featnet2 = MSINet(channel_msi)\n",
        "        self.cam = CAM()\n",
        "        self.proj_norm = LayerNorm(64)\n",
        "        self.fc1 = nn.Linear(1 * 1 * 128, 64)\n",
        "        self.fc2 = nn.Linear(64, class_num)\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "    def forward(self, x, y):\n",
        "\n",
        "        # Pre-process Image Feature\n",
        "        feature_1 = self.featnet1(x)\n",
        "        feature_2 = self.featnet2(y)\n",
        "\n",
        "        hsi_feat = feature_1.unsqueeze(1)\n",
        "        lidar_feat = feature_2.unsqueeze(1)\n",
        "        hsi, lidar = self.cam(hsi_feat, lidar_feat)\n",
        "        x = self.xcorr_depthwise(hsi, lidar)\n",
        "        y = self.xcorr_depthwise(lidar, hsi)\n",
        "        x1 = x.contiguous().view(x.size(0), -1)\n",
        "        y1 = y.contiguous().view(y.size(0), -1)\n",
        "        x = x1 + y1\n",
        "        x = F.relu(self.proj_norm(self.fc1(x)))\n",
        "        \n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        # hsi = hsi.contiguous().view(x.size(0), -1)\n",
        "        # lidar = lidar.contiguous().view(x.size(0), -1)\n",
        "        return feature_1, feature_2, x1, y1, x\n",
        "\n",
        "    def xcorr_depthwise11(self, x, kernel):\n",
        "        batch = kernel.size(0)\n",
        "        channel = kernel.size(1)\n",
        "        x = x.view(1, batch * channel, x.size(2), x.size(3))\n",
        "        kernel = kernel.view(batch, channel, kernel.size(2), kernel.size(3))\n",
        "        out = F.conv2d(x, kernel, groups= 1)\n",
        "        # out = F.relu(out)\n",
        "        out = out.view(batch, 1, out.size(2), out.size(3))\n",
        "        return out\n",
        "\n",
        "    def xcorr_depthwise(self, x, kernel):\n",
        "        batch = kernel.size(0)\n",
        "        channel = kernel.size(1)\n",
        "        x = x.view(1, batch * channel, x.size(2), x.size(3))\n",
        "        kernel = kernel.view(batch * channel, 1, kernel.size(2), kernel.size(3))\n",
        "        out = F.conv2d(x, kernel, groups=batch*channel)\n",
        "        # out = F.relu(out)\n",
        "        out = out.view(batch, channel, out.size(2), out.size(3))\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM4kogzPAniC"
      },
      "source": [
        "# 3. Data processing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A_Ndtr3AuKV"
      },
      "source": [
        "def max_min_mean(img):\n",
        "  \"\"\"\n",
        "    calculate the max value ,min value ,mean value from the image.\n",
        "  \"\"\"\n",
        "  print('max: ',np.max(img),'min: ',np.min(img),'mean: ',np.mean(img))\n",
        "\n",
        "def c(img):\n",
        "  \"\"\"\n",
        "    map the image to [0,255]\n",
        "  \"\"\"\n",
        "  return ( img - np.min(img) ) / ( np.max(img)-np.min(img) ) * 255\n",
        "\n",
        "\n",
        "def applyPCA(X, numComponents):\n",
        "  \"\"\"\n",
        "    apply PCA to the image to reduce dimensionality \n",
        "  \"\"\"\n",
        "  newX = np.reshape(X, (-1, X.shape[2]))\n",
        "  pca = PCA(n_components=numComponents, whiten=True)\n",
        "  newX = pca.fit_transform(newX)\n",
        "  newX = np.reshape(newX, (X.shape[0], X.shape[1], numComponents))\n",
        "  return newX\n",
        "\n",
        "def addZeroPadding(X, margin=2):\n",
        "  \"\"\"\n",
        "    add zero padding to the image\n",
        "  \"\"\"\n",
        "  newX = np.zeros((\n",
        "      X.shape[0] + 2 * margin,\n",
        "      X.shape[1] + 2 * margin,\n",
        "      X.shape[2]\n",
        "            ))\n",
        "  newX[margin:X.shape[0]+margin, margin:X.shape[1]+margin, :] = X\n",
        "  return newX\n",
        "\n",
        "\n",
        "def createImgCube(X ,gt ,pos:list ,windowSize=25):\n",
        "  \"\"\"\n",
        "    create Cube from pos list\n",
        "    return imagecube gt nextPos\n",
        "  \"\"\"\n",
        "  margin = (windowSize-1)//2\n",
        "  zeroPaddingX = addZeroPadding(X, margin=margin)\n",
        "  dataPatches = np.zeros((pos.__len__(), windowSize, windowSize, X.shape[2]))\n",
        "  if( pos[-1][1]+1 != X.shape[1] ):\n",
        "    nextPos = (pos[-1][0] ,pos[-1][1]+1)\n",
        "  elif( pos[-1][0]+1 != X.shape[0] ):\n",
        "    nextPos = (pos[-1][0]+1 ,0)\n",
        "  else:\n",
        "    nextPos = (0,0)\n",
        "  return np.array([zeroPaddingX[i:i+windowSize, j:j+windowSize, :] for i,j in pos ]),\\\n",
        "  np.array([gt[i,j] for i,j in pos]) ,\\\n",
        "  nextPos\n",
        "\n",
        "\n",
        "def createPos(shape:tuple, pos:tuple, num:int):\n",
        "  \"\"\"\n",
        "    creatre pos list after the given pos\n",
        "  \"\"\"\n",
        "  if (pos[0]+1)*(pos[1]+1)+num >shape[0]*shape[1]:\n",
        "    num = shape[0]*shape[1]-( (pos[0])*shape[1] + pos[1] )\n",
        "  return [(pos[0]+(pos[1]+i)//shape[1] , (pos[1]+i)%shape[1] ) for i in range(num) ]\n",
        "\n",
        "def createPosWithoutZero(hsi, gt):\n",
        "  \"\"\"\n",
        "    creatre pos list without zero labels\n",
        "  \"\"\"\n",
        "  mask = gt > 0\n",
        "  return [(i,j) for i , row  in enumerate(mask) for j , row_element in enumerate(row) if row_element]\n",
        "\n",
        "def createImgPatch(lidar, pos:list, windowSize=25):\n",
        "  \"\"\"\n",
        "    return lidar Img patches\n",
        "  \"\"\"\n",
        "  margin = (windowSize-1)//2\n",
        "  zeroPaddingLidar = np.zeros((\n",
        "      lidar.shape[0] + 2 * margin,\n",
        "      lidar.shape[1] + 2 * margin\n",
        "            ))\n",
        "  zeroPaddingLidar[margin:lidar.shape[0]+margin, margin:lidar.shape[1]+margin] = lidar\n",
        "  return np.array([zeroPaddingLidar[i:i+windowSize, j:j+windowSize] for i,j in pos ])\n",
        "  \n",
        "def splitTrainTestSet(X, gt, testRatio, randomState=111):\n",
        "  \"\"\"\n",
        "    random split data set\n",
        "  \"\"\"\n",
        "  X_train, X_test, gt_train, gt_test = train_test_split(\n",
        "      X, gt, test_size=testRatio, random_state=randomState, stratify=gt)\n",
        "  return X_train, X_test, gt_train, gt_test\n",
        "\n",
        "def minmax_normalize(array):    \n",
        "    amin = np.min(array)\n",
        "    amax = np.max(array)\n",
        "    return (array - amin) / (amax - amin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ4XnH3qBBCe"
      },
      "source": [
        "# 4. Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTJxj8OyBBXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9556d637-5bf7-464c-f552-763533db44f0"
      },
      "source": [
        "\n",
        "data_traingt = sio.loadmat(os.path.join(data_path, 'trento_mask_train.mat'))['mask_train']\n",
        "data_testgt = sio.loadmat(os.path.join(data_path, 'trento_mask_test.mat'))['mask_test']\n",
        "data_hsi = sio.loadmat(os.path.join(data_path, 'trento_hsi.mat'))['trento_hsi']\n",
        "data_msi = sio.loadmat(os.path.join(data_path, 'trento_lidar.mat'))['trento_lidar']\n",
        "# data_msi = h5py.File(os.path.join(data_path, 'HHK_msi.mat'))\n",
        "# data_msi = data_msi['HHK_msi'][:]\n",
        "# data_msi= np.transpose(data_msi,(2,1,0))\n",
        "\n",
        "data_hsi = minmax_normalize(data_hsi)\n",
        "data_msi = minmax_normalize(data_msi)\n",
        "height, width, c = data_msi.shape\n",
        "\n",
        "# training / testing set for 2D-CNN\n",
        "\n",
        "train_hsiCube, train_labels, _ = createImgCube(\tdata_hsi, data_traingt, createPosWithoutZero(data_hsi, data_traingt), windowSize=windowSize)\n",
        "train_patches, _, _ = createImgCube(data_msi, data_traingt, createPosWithoutZero(data_msi, data_traingt), windowSize=windowSize)\n",
        "\n",
        "# data augmentation if need\n",
        "\n",
        "Xh = []\n",
        "Xl = []\n",
        "y = []\n",
        "for i in range(train_hsiCube.shape[0]):\n",
        "    Xh.append(train_hsiCube[i])\n",
        "    Xl.append(train_patches[i])\n",
        "\n",
        "    noise = np.random.normal(0.0, 0.01, size=train_hsiCube[0].shape)\n",
        "    noise2 = np.random.normal(0.0, 0.01, size=train_patches[0].shape)\n",
        "    Xh.append(np.flip(train_hsiCube[i] + noise, axis=1))\n",
        "    Xl.append(np.flip(train_patches[i] + noise2, axis=1))\n",
        "\n",
        "    k = np.random.randint(4)\n",
        "    Xh.append(np.rot90(train_hsiCube[i], k=k))\n",
        "    Xl.append(np.rot90(train_patches[i], k=k))\n",
        "\n",
        "    y.append(train_labels[i])\n",
        "    y.append(train_labels[i])\n",
        "    y.append(train_labels[i])\n",
        "\n",
        "train_labels = np.asarray(y, dtype=np.int8)\n",
        "train_hsiCube = np.asarray(Xh, dtype=np.float32)\n",
        "train_patches = np.asarray(Xl, dtype=np.float32)\n",
        "train_hsiCube = torch.from_numpy(train_hsiCube.transpose(0, 3, 1, 2)).float()\n",
        "train_patches = torch.from_numpy(train_patches.transpose(0, 3, 1, 2)).float()\n",
        "\n",
        "X_train, X_test, gt_train, gt_test = splitTrainTestSet(train_hsiCube, train_labels, valRatio, randomState=111)\n",
        "X_train_2, X_test_2, _, _ = splitTrainTestSet(train_patches, train_labels, valRatio, randomState=111)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(\"Creating dataloader\")\n",
        "\n",
        "class TrainDS(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        self.len = gt_train.shape[0]\n",
        "        self.hsi = torch.FloatTensor(X_train)\n",
        "        self.lidar = torch.FloatTensor(X_train_2)\n",
        "        self.labels = torch.LongTensor(gt_train - 1)\n",
        "    def __getitem__(self, index):\n",
        "        return self.hsi[index], self.lidar[index], self.labels[index]\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\"\"\" Testing dataset\"\"\"\n",
        "\n",
        "class TestDS(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        self.len = gt_test.shape[0]\n",
        "        self.hsi = torch.FloatTensor(X_test)\n",
        "        self.lidar = torch.FloatTensor(X_test_2)\n",
        "        self.labels = torch.LongTensor(gt_test - 1)\n",
        "    def __getitem__(self, index):\n",
        "        return self.hsi[index], self.lidar[index], self.labels[index]\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# create trainloader and valloader -- (testload)\n",
        "trainset = TrainDS()\n",
        "valset = TestDS()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=64, shuffle=True, num_workers=0)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=valset, batch_size=64, shuffle=False, num_workers=0)\n",
        "\n",
        "print(\"Finish!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1965, 63, 11, 11])\n",
            "torch.Size([492, 63, 11, 11])\n",
            "Creating dataloader\n",
            "Finish!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxQ57lsoBsIk"
      },
      "source": [
        "# 5. The loss function\n",
        "\n",
        "1.   Loss1: The consistency loss\n",
        "2.   Loss2: The distinctive loss\n",
        "3.   Loss3: The classification loss\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgM_E3XHBg7C"
      },
      "source": [
        "def calc_label_sim(label_1,label_2):\n",
        "\n",
        "    batch_size = label_1.shape[0]\n",
        "    label = torch.zeros(batch_size, class_num).scatter_(1, label_1.unsqueeze(1).cpu(), 1)\n",
        "    sim = label.float().mm(label.float().t()).cuda()\n",
        "    return sim\n",
        "def calc_loss(feature_1, feature_2, hsi_1, lidar_1, outputs, labels, alpha, beta):\n",
        "\n",
        "    cos = lambda x, y: x.mm(y.t()) / ((x ** 2).sum(1, keepdim=True).sqrt().mm((y ** 2).sum(1, keepdim=True).sqrt().t())).clamp(min=1e-6) / 2.\n",
        "    theta = cos(hsi_1, lidar_1)\n",
        "    sim = calc_label_sim(labels, labels)\n",
        "    theta1 = cos(hsi_1, hsi_1)\n",
        "    theta2 = cos(lidar_1, lidar_1)\n",
        "\n",
        "    term1= ((1+torch.exp(theta)).log() + sim * theta).mean()\n",
        "    term2 = ((1 + torch.exp(theta1)).log() + sim * theta1).mean()\n",
        "    term3 = ((1 + torch.exp(theta2)).log() + sim * theta2).mean()\n",
        "    loss2 = term1 + term2 + term3\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loss3 = criterion(outputs, labels)\n",
        "    loss1 = torch.mean(torch.pow(feature_1 - feature_2, 2))\n",
        "\n",
        "    loss_sum = loss3 + alpha * loss2 + beta * loss1\n",
        "    return loss_sum.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdMnyTbeCO6T"
      },
      "source": [
        "Define training and testing layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjBG9og2CPBV"
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i, (inputs_1, inputs_2, labels) in enumerate(train_loader):\n",
        "        inputs_1, inputs_2 = inputs_1.to(device), inputs_2.to(device)\n",
        "\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        feature_1, feature_2, hsi_1, lidar_1, outputs = model(inputs_1, inputs_2)\n",
        "        loss = calc_loss(feature_1, feature_2, hsi_1, lidar_1, outputs, labels, alpha =0.01, beta = 0.01)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print('[Epoch: %d] [loss avg: %.4f] [current loss: %.4f]' %(epoch + 1, total_loss/(epoch+1), loss.item()))\n",
        "\n",
        "def test(model, device, val_loader):\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    feature =[]\n",
        "    flabel = []\n",
        "    for inputs_1, inputs_2, labels in val_loader:\n",
        "  \n",
        "        inputs_1, inputs_2 = inputs_1.to(device), inputs_2.to(device)\n",
        "        _, _, _, _, outputs = model(inputs_1, inputs_2)\n",
        "        feature.append(outputs.detach().cpu().numpy())\n",
        "        outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
        "        if count == 0:\n",
        "            y_pred_test =  outputs\n",
        "            test_labels = labels\n",
        "            count = 1\n",
        "        else:\n",
        "            y_pred_test = np.concatenate((y_pred_test, outputs))\n",
        "            test_labels = np.concatenate((test_labels, labels))\n",
        "    classification = classification_report(test_labels, y_pred_test, digits=4)\n",
        "      \n",
        "    sio.savemat('feature.mat', {'feature': feature})\n",
        "    a = 0\n",
        "    for c in range(len(y_pred_test)):\n",
        "      if test_labels[c]==y_pred_test[c]:\n",
        "        a = a+1\n",
        "    sio.savemat('test_labels.mat', {'test_labels': test_labels})\n",
        "    print(classification)\n",
        "    acc = a/len(y_pred_test)*100\n",
        "    print('%.2f' % (a/len(y_pred_test)*100))\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSAc_kbLAxP"
      },
      "source": [
        "# 6. Running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSy2Vxx_LA5P"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net(channel_hsi, channel_msi, class_num).to(device)\n",
        "\n",
        "params_to_update = list(model.parameters())\n",
        "\n",
        "# optimizer = torch.optim.Adam(params_to_update, lr=lr, betas=betas, eps=1e-8, weight_decay=0.0005)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=0.0005)\n",
        "\n",
        "# if num_epochs % 50 == 0:\n",
        "#     for p in optimizer.param_groups:p['lr'] *= 0.9\n",
        "#     lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
        "#     print (lr_list)\n",
        "\n",
        "best_acc = 0\n",
        "for epoch in range(num_epochs):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    acc = test(model, device, val_loader)\n",
        "    if acc >= best_acc:\n",
        "        best_acc = acc\n",
        "        print(\"save model\")\n",
        "        torch.save(model.state_dict(), './model/model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR3aPwlILr4T"
      },
      "source": [
        "# 7. Record the final test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jkC7NQTLsA4"
      },
      "source": [
        "model = Net(channel_hsi, channel_msi, class_num).eval().cuda()\n",
        "model.load_state_dict(torch.load('./model/model.pth'))\n",
        "\n",
        "margin = (windowSize-1)//2\n",
        "data_hsi = addZeroPadding(data_hsi, margin=margin)\n",
        "data_msi = addZeroPadding(data_msi, margin=margin)\n",
        "\n",
        "# Prediction\n",
        "outputs = np.zeros((height, width))\n",
        "# feature = np.zeros(test_hsiCube.shape[0], class_num)\n",
        "for i in range(height):\n",
        "    for j in range(width):\n",
        "        if int(data_testgt[i, j]) != 0:\n",
        "            #     continue\n",
        "            # else :\n",
        "            image_patch = data_hsi[i:i+windowSize, j:j+windowSize, :]\n",
        "            image_patch = image_patch.reshape(1, image_patch.shape[0], image_patch.shape[1], image_patch.shape[2])\n",
        "            X_test_image = torch.FloatTensor(image_patch.transpose(0, 3, 1, 2)).to(device)\n",
        "\n",
        "            image_patch1 = data_msi[i:i+windowSize, j:j+windowSize, :]\n",
        "            image_patch1 = image_patch1.reshape(1, image_patch1.shape[0], image_patch1.shape[1], image_patch1.shape[2])\n",
        "            X_test_image1 = torch.FloatTensor(image_patch1.transpose(0, 3, 1, 2)).to(device)\n",
        "\n",
        "            _, _, _, _, prediction = model(X_test_image, X_test_image1)\n",
        "            prediction = np.argmax(prediction.detach().cpu().numpy(), axis=1)\n",
        "            outputs[i][j] = prediction + 1\n",
        "    if i % 20 == 0:\n",
        "        print('... ... row ', i, ' handling ... ...')\n",
        "sio.savemat('result.mat', {'output': outputs})\n",
        "print('ALL Finish!!')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
